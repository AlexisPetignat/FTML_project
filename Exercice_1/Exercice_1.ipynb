{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30b8f4e-9a22-4897-9b9a-cacbefeef210",
   "metadata": {},
   "source": [
    "# FTML Project Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63932b1-e033-4e05-9f83-99f8b6eeefae",
   "metadata": {},
   "source": [
    "This is the first exercise of the FTML project.\n",
    "\n",
    "## Question 1\n",
    "\n",
    "In this exercise, we will talk about politics. The events, characters, and situations described in this document are entirely fictional and are not intended to represent or reflect any real individuals, institutions, or occurrences. Any resemblance to actual events or persons, living or dead, is purely coincidental.\n",
    "\n",
    "Anyways, our subject for this supervised learning will be the signature of decrees by Danold Trump, resulting in a market dropdown. \n",
    "\n",
    "- Our input space X is N² as a vector (n, t), with n the number of decrees signed this day and t, how many tweets Danold Trump posted about these decrees (both n and t natural and positive).\n",
    "\n",
    "  \n",
    "  \n",
    "- Our output space is a Natural y, representing the market Dropdown for the same day, in percents and as a discrete value. We consider this number natural and strictly positive.\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "- The relation between X (n, t) and Y are as follow:<p style=\"text-align:center;\">Y = n * S + t</p>We introduce S a random variable, following a uniform distribution in {1, 2, 3}. Y is how many bilions the market has lost.\n",
    "  \n",
    "\n",
    "- We will use Square Loss as the loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0625613-940d-4f5e-b44e-a90fad875dbf",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Let us define the Bayes predictor for this situation:\n",
    "\n",
    "- First, we identify the random component as the variable S, which's expectation can be calculated as follow:\n",
    "\n",
    "$$E[S] = \\frac{1 + 2 + 3}{3}  = 2$$\n",
    "\n",
    "- Therefore, we can calculate the Bayes estimator for our settings:\n",
    "\n",
    "$$f^*(n, t) = 2n + t$$\n",
    "\n",
    "---\n",
    "## Let us calculate the Bayes Risk for this setting\n",
    "\n",
    "- We must calculate the real risk of the bayes estimator, which is defined as the average loss for the estimator, defined as follow:\n",
    "\n",
    "$$\n",
    "R(f^*(n, t)) = \\mathbb{E}\\left[(Y - (n \\cdot S + t))^2\\right]\n",
    "$$\n",
    "\n",
    "- We now compute the variance of Y - f*, which is the variance of f*(n, t), calculated as follow\n",
    "\n",
    "$$\n",
    "\\text{Var}(f^*) = \\text{Var}(n \\cdot S + t) = n^2 \\cdot \\text{Var}(S)\n",
    "$$\n",
    "\n",
    "- Then we compute Var(S) as follow:\n",
    "\n",
    "$$\n",
    "\\text{Var}(S) = \\mathbb{E}[S^2] - \\left(\\mathbb{E}[S]\\right)^2 = \\frac{1^2 + 2^2 + 3^2}{3} - 4 = \\frac{14}{3} - 4 = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "$$\\newline\\newline$$\n",
    "\n",
    "\n",
    "\n",
    "Therefore, our Bayes is risk is 2n²/3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801c1f0-d177-4b94-8d0e-69fb765bfcac",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "For this question, we will define a new estimator and compute its associated risks on a test set.\n",
    "\n",
    "$$g^* = n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac96e5c-9602-4ca2-9a80-641afdbb7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_SIZE = 1_000_000\n",
    "\n",
    "# bayes estimator\n",
    "bayes_estimator = lambda n, t: 2 * n + t\n",
    "\n",
    "# bad estimator\n",
    "g = lambda n, t: n\n",
    "\n",
    "n = np.random.randint(low = 0, high = 10, size = 1)[0]\n",
    "t = np.random.randint(low = 0, high = 20, size = 1)[0]\n",
    "s = np.random.randint(low = 1, high = 4,  size = SAMPLE_SIZE)\n",
    "\n",
    "Y = s * n + t\n",
    "\n",
    "X_bayes = bayes_estimator(n, t)\n",
    "X_g = g(n, t)\n",
    "\n",
    "\n",
    "# Mean absolute errors\n",
    "error_g = np.mean((X_g - Y) ** 2)\n",
    "error_bayes = np.mean((X_bayes - Y) ** 2)\n",
    "\n",
    "print(f\"Settings: n = {n}, t = {t}\")\n",
    "print(f\"Computed Bayes Risk: {n**2 * 2 / 3}\")\n",
    "print(\"\")\n",
    "print(\"Mean absolute error for Bayes estimator: \", error_bayes)\n",
    "print(\"Mean absolute error for estimator g: =\", error_g)\n",
    "\n",
    "assert error_bayes < error_g, \"the generalization error is smaller for f∗ than for g\"\n",
    "\n",
    "plt.title(\"Risk comparison\")\n",
    "plt.bar(x=\"Bayesian estimator real risk\", height=error_bayes)\n",
    "plt.bar(x=\"Bad estimator real risk\",      height=error_g)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec2ac0-d7f6-4b19-84d7-f539e7ad1ea5",
   "metadata": {},
   "source": [
    "It is pretty clear that the Bayes estimator yields better results than the estimator g. We also notice, as expected that the Mean absolute error for the Bayes estimator is nearing the computed Bayes risk each time we run the simulation, with a sample size of 1000000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftml-venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
