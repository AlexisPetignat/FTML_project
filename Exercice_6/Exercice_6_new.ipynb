{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTML Project Exercice 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset presentation and problem statement\n",
    "\n",
    "Automatic fish species classification from underwater images is a computer vision task with real-world applications in marine conservation and industrial automation. This supervised learning problem consists of identifying the species of a fish based on its visual features in a low-resolution image (resized to 32×32 pixels). Accurate classification models can be used aboard fishing vessels to automate sorting by species, for example, to direct catches to the appropriate storage or freezing processes. Such systems can also support conservation efforts by identifying and releasing non-target or protected species in real time, helping ensure compliance with marine biodiversity regulations. We try to solve this problem by using the Fish4Knowledge project.\n",
    "\n",
    "The Fish Recognition Ground-Truth dataset, developed under the Fish4Knowledge project, includes 27,370 manually labeled fish images organized into 23 species-based groups. These images are extracted from underwater video footage using specialized detection and tracking software and verified with guidance from marine biologists. Each species is stored in a separate archive containing the corresponding fish images and binary masks, with filenames reflecting unique tracking and fish identifiers. The dataset is notably imbalanced, with certain species represented by thousands of images and others by just a few dozen.\n",
    "\n",
    "You can find all the data in the data/ folder, and here is the correspondence between directories names and species:\n",
    "\n",
    "| ID.species                   | Detection | Trajectory |\n",
    "|-----------------------------|-------------|--------------|\n",
    "| 01.Dascyllus reticulatus    | 12112       | 4240         |\n",
    "| 02.Plectroglyphidodon dickii| 2683        | 1225         |\n",
    "| 03.Chromis chrysura         | 3593        | 1175         |\n",
    "| 04.Amphiprion clarkii       | 4049        | 1021         |\n",
    "| 05.Chaetodon lunulatus      | 2534        | 536          |\n",
    "| 06.Chaetodon trifascialis   | 190         | 79           |\n",
    "| 07.Myripristis kuntee       | 450         | 71           |\n",
    "| 08.Acanthurus nigrofuscus   | 218         | 71           |\n",
    "| 09.Hemigymnus fasciatus     | 241         | 58           |\n",
    "| 10.Neoniphon sammara        | 299         | 53           |\n",
    "| 11.Abudefduf vaigiensis     | 98          | 42           |\n",
    "| 12.Canthigaster valentini   | 147         | 28           |\n",
    "| 13.Pomacentrus moluccensis  | 181         | 27           |\n",
    "| 14.Zebrasoma scopas         | 90          | 23           |\n",
    "| 15.Hemigymnus melapterus    | 42          | 16           |\n",
    "| 16.Lutjanus fulvus          | 206         | 15           |\n",
    "| 17.Scolopsis bilineata      | 49          | 8            |\n",
    "| 18.Scaridae                 | 56          | 5            |\n",
    "| 19.Pempheris vanicolensis   | 29          | 6            |\n",
    "| 20.Zanclus cornutus         | 21          | 6            |\n",
    "| 21.Neoglyphidodon nigroris | 16          | 8            |\n",
    "| 22.Balistapus undulatus     | 41          | 6            |\n",
    "| 23.Siganus fuscescens       | 25          | 6            |\n",
    "\n",
    "Each picture filename follow the format: `fish_tracking-id_fish-id.png`. You can have multiple pictures of the same fish: in this case, the tracking-id of the two pictures will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T12:05:01.848064Z",
     "iopub.status.busy": "2025-07-03T12:05:01.847818Z",
     "iopub.status.idle": "2025-07-03T12:05:03.091644Z",
     "shell.execute_reply": "2025-07-03T12:05:03.090864Z",
     "shell.execute_reply.started": "2025-07-03T12:05:01.848045Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_image(file_path: Path, label: int, image_size=(32, 32), normalize=True):\n",
    "    try:\n",
    "        img = cv2.imread(str(file_path))\n",
    "        if img is None:\n",
    "            raise ValueError(\"Image loading failed.\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)\n",
    "        if normalize:\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "        return {\"image\": img, \"label\": label}\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_images_parallel(data_dir: str, image_size=(32, 32), normalize=True, max_workers=8):\n",
    "    data_dir = Path(data_dir)\n",
    "    tasks = []\n",
    "\n",
    "    # Prepare all file paths and labels first\n",
    "    for class_index in range(1, 24):\n",
    "        folder_name = f\"fish_{class_index:02d}\"\n",
    "        folder_path = data_dir / folder_name\n",
    "        label = class_index - 1\n",
    "\n",
    "        if not folder_path.exists():\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')):\n",
    "                file_path = folder_path / file\n",
    "                tasks.append((file_path, label))\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_image, path, label, image_size, normalize) for path, label in tasks]\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Loading images\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "def split_dataset(df: pd.DataFrame, test_size=0.2, random_state=42):\n",
    "    return train_test_split(df, test_size=test_size, stratify=df[\"label\"], random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T12:12:32.197203Z",
     "iopub.status.busy": "2025-07-03T12:12:32.196928Z",
     "iopub.status.idle": "2025-07-03T12:12:43.577149Z",
     "shell.execute_reply": "2025-07-03T12:12:43.576559Z",
     "shell.execute_reply.started": "2025-07-03T12:12:32.197184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 27370/27370 [00:10<00:00, 2704.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = load_images_parallel(\"/kaggle/input/fish-zip/\", image_size=(32, 32), normalize=True, max_workers=16)\n",
    "\n",
    "X = np.stack(df[\"image\"].values)  # shape (N, 32, 32, 3)\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Flatten images for classical ML\n",
    "X_flat = X.reshape((X.shape[0], -1))\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_flat, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above preprocesses a fish image dataset by loading images from 23 class folders named `fish_01` to `fish_23`. Each image is read in parallel using a thread pool to speed up processing. The images are converted from BGR to RGB color space, resized to 32x32 pixels (mainly for performance purposes), and normalized to have pixel values between 0 and 1. Successfully processed images and their corresponding class labels are collected into a pandas DataFrame. Finally, the dataset is split into training and testing sets with stratified sampling to maintain class balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection and optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements a hyperparameter optimization framework using Optuna to identify the best classification model and its optimal hyperparameters among four candidates: Random Forest, XGBoost, CatBoost, and a ResNet-18 based deep learning model. These specific models were chosen to have a diverse range of classification approaches: traditional machine learning techniques with Random Forest, XGBoost, and CatBoost (that will allow to perform strongly on categories that have a small support), and deep convolutional neural network architecture Resnet18, that is tailored for image classification.\n",
    "\n",
    "Due to limited computational resources, we did hyperparameter optimization within a restricted parameter range and selected only four models for comparison. We used kaggle GPUs to go faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# === For ResNet: reshape and convert ===\n",
    "X_train_img = X_train.reshape(-1, 3, 32, 32).astype(np.float32)\n",
    "X_val_img = X_val.reshape(-1, 3, 32, 32).astype(np.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_img)\n",
    "X_val_tensor = torch.tensor(X_val_img)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=64)\n",
    "\n",
    "# === Objective function for Optuna ===\n",
    "def objective(trial):\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"RandomForest\", \"XGBoost\", \"CatBoost\", \"ResNet\"])\n",
    "\n",
    "    if classifier_name == \"RandomForest\":\n",
    "        n_estimators = trial.suggest_int(\"rf_n_estimators\", 50, 200)\n",
    "        max_depth = trial.suggest_int(\"rf_max_depth\", 5, 20)\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "\n",
    "    elif classifier_name == \"XGBoost\":\n",
    "        n_estimators = trial.suggest_int(\"xgb_n_estimators\", 50, 200)\n",
    "        max_depth = trial.suggest_int(\"xgb_max_depth\", 3, 10)\n",
    "        learning_rate = trial.suggest_float(\"xgb_learning_rate\", 0.05, 0.3)\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=42,\n",
    "            verbosity=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "\n",
    "    elif classifier_name == \"CatBoost\":\n",
    "        n_estimators = trial.suggest_int(\"cat_n_estimators\", 50, 200)\n",
    "        depth = trial.suggest_int(\"cat_depth\", 4, 8)\n",
    "        learning_rate = trial.suggest_float(\"cat_learning_rate\", 0.05, 0.3)\n",
    "        clf = CatBoostClassifier(\n",
    "            iterations=n_estimators,\n",
    "            depth=depth,\n",
    "            learning_rate=learning_rate,\n",
    "            task_type=\"GPU\",\n",
    "            devices=\"0\",\n",
    "            verbose=0,\n",
    "            random_seed=42\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "\n",
    "    else:  # ResNet\n",
    "        num_classes = 23\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        model = model.cuda()\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(3):  # Short for fast optimization\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.cuda(), yb.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(xb)\n",
    "                loss = criterion(output, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.cuda(), yb.cuda()\n",
    "                outputs = model(xb)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += yb.size(0)\n",
    "                correct += (predicted == yb).sum().item()\n",
    "\n",
    "        acc = correct / total\n",
    "\n",
    "    return acc\n",
    "\n",
    "# === Run Optuna study ===\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "# === Print best trial ===\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Accuracy: {trial.value:.4f}\")\n",
    "print(\"  Best hyperparameters:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To our surprise, XGBoost outperformed other models in the fish species classification. Our explanation is that the dataset has imbalanced and heterogeneous data distributions:the dataset has significant class imbalance, with some species having thousands of samples while others only a few dozen. Tree-based ensemble methods like XGBoost inherently manage such imbalance better by focusing on difficult-to-classify samples through gradient boosting. Additionally XGBoost is advantageous when working with low-resolution images.\n",
    "\n",
    "We trained a XGBoost model with parameters we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:02:16.260827Z",
     "iopub.status.busy": "2025-07-03T13:02:16.260554Z",
     "iopub.status.idle": "2025-07-03T13:04:05.527876Z",
     "shell.execute_reply": "2025-07-03T13:04:05.527121Z",
     "shell.execute_reply.started": "2025-07-03T13:02:16.260808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.259431216634468,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=198, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.259431216634468,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=198, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.259431216634468,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=198, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# Rebuild the best model\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=best_params[\"xgb_n_estimators\"],\n",
    "    max_depth=best_params[\"xgb_max_depth\"],\n",
    "    learning_rate=best_params[\"xgb_learning_rate\"],\n",
    "    tree_method=\"gpu_hist\",\n",
    "    predictor=\"gpu_predictor\",\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T13:04:09.272715Z",
     "iopub.status.busy": "2025-07-03T13:04:09.272048Z",
     "iopub.status.idle": "2025-07-03T13:04:09.521193Z",
     "shell.execute_reply": "2025-07-03T13:04:09.520459Z",
     "shell.execute_reply.started": "2025-07-03T13:04:09.272670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (XGBoost):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9590    0.9839    0.9713      2422\n",
      "           1     0.9683    0.9683    0.9683       537\n",
      "           2     0.9607    0.9527    0.9567       719\n",
      "           3     0.9841    0.9914    0.9877       810\n",
      "           4     0.9748    0.9921    0.9834       507\n",
      "           5     0.9310    0.7105    0.8060        38\n",
      "           6     0.9659    0.9444    0.9551        90\n",
      "           7     0.9118    0.7045    0.7949        44\n",
      "           8     0.9211    0.7292    0.8140        48\n",
      "           9     1.0000    0.9667    0.9831        60\n",
      "          10     0.8571    0.6000    0.7059        20\n",
      "          11     0.8667    0.8966    0.8814        29\n",
      "          12     1.0000    0.8889    0.9412        36\n",
      "          13     1.0000    0.5000    0.6667        18\n",
      "          14     1.0000    0.2500    0.4000         8\n",
      "          15     0.9070    0.9512    0.9286        41\n",
      "          16     0.8333    0.5000    0.6250        10\n",
      "          17     1.0000    0.8182    0.9000        11\n",
      "          18     1.0000    0.3333    0.5000         6\n",
      "          19     1.0000    0.2500    0.4000         4\n",
      "          20     1.0000    0.6667    0.8000         3\n",
      "          21     1.0000    0.6250    0.7692         8\n",
      "          22     1.0000    1.0000    1.0000         5\n",
      "\n",
      "    accuracy                         0.9644      5474\n",
      "   macro avg     0.9583    0.7489    0.8147      5474\n",
      "weighted avg     0.9642    0.9644    0.9627      5474\n",
      "\n",
      "Accuracy              : 0.9644\n",
      "F1 Score (macro)      : 0.8147\n",
      "F1 Score (weighted)   : 0.9627\n",
      "Precision (macro)     : 0.9583\n",
      "Recall (macro)        : 0.7489\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_val, y_pred, digits=4)\n",
    "print(\"Classification Report (XGBoost):\\n\")\n",
    "print(report)\n",
    "\n",
    "# Macro metrics\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_val, y_pred, average='weighted')\n",
    "precision_macro = precision_score(y_val, y_pred, average='macro')\n",
    "recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy              :\", round(acc, 4))\n",
    "print(\"F1 Score (macro)      :\", round(f1_macro, 4))\n",
    "print(\"F1 Score (weighted)   :\", round(f1_weighted, 4))\n",
    "print(\"Precision (macro)     :\", round(precision_macro, 4))\n",
    "print(\"Recall (macro)        :\", round(recall_macro, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model achieved strong overall performance on the fish species classification task, with an accuracy of 96.44%. The weighted F1 score, which accounts for class imbalance, was also high at 0.96, indicating that the model performs well across most species. However, the macro-average F1 score was lower at 0.81, reflecting that the model struggles more with classes that have fewer samples. Precision remains high across all classes, but recall drops noticeably for smaller classes, meaning some fish species with limited data are harder for the model to correctly identify."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7787892,
     "sourceId": 12352959,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
